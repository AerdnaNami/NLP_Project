{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyWAwWSWJ8WI",
        "outputId": "66a8c124-d2f9-4260-c553-0d8bef3a1e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, rank_bm25, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 rank_bm25-0.2.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets rank_bm25 transformers nltk pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "from rank_bm25 import BM25Okapi\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmv6F36NMgnd",
        "outputId": "3d4437f7-31e0-4410-cf96-b54e30df1c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define functions\n",
        "def create_qa_dataframe(ds, split):\n",
        "    titles, questions, answers, evidence = [], [], [], []\n",
        "    for id in range(len(ds[split])):\n",
        "        title = ds[split]['title'][id]\n",
        "        for i in range(len(ds[split][id]['qas']['question'])):\n",
        "            for j in range(len(ds[split][id]['qas']['answers'][i]['answer'])):\n",
        "                if len(ds[split][id]['qas']['answers'][i]['answer'][j]['extractive_spans']) > 0:\n",
        "                    titles.append(title)\n",
        "                    evidence.append(ds[split][id]['qas']['answers'][i]['answer'][j]['evidence'])\n",
        "                    questions.append(ds[split][id]['qas']['question'][i])\n",
        "                    answers.append(ds[split][id]['qas']['answers'][i]['answer'][j]['extractive_spans'][0])\n",
        "    return pd.DataFrame({'title': titles, 'question': questions, 'answer': answers, 'evidence': evidence})\n",
        "\n",
        "def extract_full_papers(ds, split):\n",
        "    papers = []\n",
        "    for doc in ds[split]:\n",
        "        if 'title' not in doc or 'full_text' not in doc:\n",
        "            continue\n",
        "        paper_detail = {'title': doc['title'], 'paragraphs': []}\n",
        "        for section in doc['full_text'].get('paragraphs', []):\n",
        "            paper_detail['paragraphs'].extend([para for para in section if para.strip()])\n",
        "        papers.append(paper_detail)\n",
        "    return pd.DataFrame(papers)\n",
        "\n",
        "def combine_questions_and_papers(df, papers_df):\n",
        "    papers_df = papers_df.rename(columns={'paragraphs': 'full_paper'})\n",
        "    combined_df = pd.merge(df, papers_df, on='title', how='inner')\n",
        "    return combined_df\n"
      ],
      "metadata": {
        "id": "eA2hxIpgKGas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_qa_pipeline(model_checkpoint):\n",
        "    return pipeline(\"question-answering\", model=model_checkpoint, device=-1)\n",
        "\n",
        "def process_bm25_qa(df_row, k=5):\n",
        "    question = df_row['question']\n",
        "    paper_paragraphs = df_row['full_paper']\n",
        "    tokenized_paragraphs = [word_tokenize(paragraph.lower()) for paragraph in paper_paragraphs]\n",
        "    bm25 = BM25Okapi(tokenized_paragraphs)\n",
        "    tokenized_question = word_tokenize(question.lower())\n",
        "    scores = bm25.get_scores(tokenized_question)\n",
        "    ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n",
        "    return [(paper_paragraphs[i], scores[i]) for i in ranked_indices]\n",
        "\n",
        "def process_qa(df_row, qa_pipeline, top_paragraphs):\n",
        "    question = df_row['question']\n",
        "    best_answer = None\n",
        "    best_score = -1\n",
        "    best_context = None\n",
        "    for paragraph, score in top_paragraphs:\n",
        "        answer = qa_pipeline(question=question, context=paragraph)\n",
        "        if answer['score'] > best_score:\n",
        "            best_answer = answer['answer']\n",
        "            best_score = answer['score']\n",
        "            best_context = paragraph\n",
        "    return {'question': question, 'answer': best_answer, 'confidence': best_score, 'context': best_context}\n",
        "\n",
        "def compute_exact_match(prediction, ground_truth):\n",
        "    if not isinstance(prediction, str) or not isinstance(ground_truth, str):\n",
        "        return 0\n",
        "    return int(prediction.strip().lower() == ground_truth.strip().lower())\n",
        "\n",
        "def compute_f1(prediction, ground_truth):\n",
        "    if not isinstance(prediction, str) or not isinstance(ground_truth, str):\n",
        "        return 0\n",
        "    pred_tokens = prediction.strip().lower().split()\n",
        "    truth_tokens = ground_truth.strip().lower().split()\n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    precision = len(common_tokens) / len(pred_tokens)\n",
        "    recall = len(common_tokens) / len(truth_tokens)\n",
        "    return 2 * (precision * recall) / (precision + recall)"
      ],
      "metadata": {
        "id": "Hv84-1-XKMuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_results(results_df, ground_truth_df):\n",
        "    evaluation_df = pd.merge(results_df, ground_truth_df[['question', 'answer']], on='question', suffixes=('_predicted', '_ground_truth'))\n",
        "    exact_matches = []\n",
        "    f1_scores = []\n",
        "    for _, row in evaluation_df.iterrows():\n",
        "        pred_answer = row['answer_predicted']\n",
        "        true_answer = row['answer_ground_truth']\n",
        "        exact_matches.append(compute_exact_match(pred_answer, true_answer))\n",
        "        f1_scores.append(compute_f1(pred_answer, true_answer))\n",
        "    evaluation_df['exact_match'] = exact_matches\n",
        "    evaluation_df['f1_score'] = f1_scores\n",
        "    average_exact_match = sum(exact_matches) / len(exact_matches) * 100\n",
        "    average_f1_score = sum(f1_scores) / len(f1_scores) * 100\n",
        "    return average_exact_match, average_f1_score, evaluation_df"
      ],
      "metadata": {
        "id": "xwjV42gBMyU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Qasper dataset\n",
        "ds = load_dataset(\"allenai/qasper\")\n",
        "split = 'test'\n",
        "\n",
        "# Prepare DataFrames\n",
        "df = create_qa_dataframe(ds, split)\n",
        "papers_df = extract_full_papers(ds, split)\n",
        "df = combine_questions_and_papers(df, papers_df)\n",
        "\n",
        "# Load models\n",
        "roberta_pipeline = create_qa_pipeline(\"ImanAndrea/roberta-finetuned-paperQA\")\n",
        "bert_pipeline = create_qa_pipeline(\"ImanAndrea/bert-finetuned-paperQA\")\n",
        "distilbert_pipeline = create_qa_pipeline(\"ImanAndrea/distilbert-finetuned-paperQA\")"
      ],
      "metadata": {
        "id": "n5h1AswpKRhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models\n",
        "results = {'model': [], 'exact_match': [], 'f1_score': []}\n",
        "\n",
        "for model_name, qa_pipeline in {\n",
        "    \"roberta\": roberta_pipeline,\n",
        "    \"bert\": bert_pipeline,\n",
        "    \"distilbert\": distilbert_pipeline\n",
        "}.items():\n",
        "    model_results = []\n",
        "    for _, row in df.iterrows():\n",
        "        top_paragraphs = process_bm25_qa(row, k=5)\n",
        "        qa_result = process_qa(row, qa_pipeline, top_paragraphs)\n",
        "        model_results.append(qa_result)\n",
        "    results_df = pd.DataFrame(model_results)\n",
        "    em, f1, evaluation_df = evaluate_results(results_df, df)\n",
        "    results['model'].append(model_name)\n",
        "    results['exact_match'].append(em)\n",
        "    results['f1_score'].append(f1)\n",
        "\n",
        "results_summary = pd.DataFrame(results)\n",
        "print(\"Summary:\")\n",
        "print(results_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ysMCtoMKZFm",
        "outputId": "d38bef4b-a8cf-4f22-b2ec-97aa6beaa4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "        model  exact_match   f1_score\n",
            "0     roberta     3.777994  12.371602\n",
            "1        bert     3.855891  12.265795\n",
            "2  distilbert     4.148004  12.120928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwNMI8h8KgVi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}